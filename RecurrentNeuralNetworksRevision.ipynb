{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "If you haven't already, please follow the [setup instructions](https://jennselby.github.io/MachineLearningCourseNotes/#setup-and-tools) to get all of the necessary software (Github is optional)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation/Sources\n",
    "* [Class Notes](https://jennselby.github.io/MachineLearningCourseNotes/#recurrent-neural-networks)\n",
    "* [https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/](https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/) for information on sequence classification with keras\n",
    "* [https://keras.io/](https://keras.io/) Keras API documentation\n",
    "* [Keras recurrent tutorial](https://github.com/Vict0rSch/deep_learning/tree/master/keras/recurrent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Understand the Weight in RNNs\n",
    "\n",
    "## Part A: Exploring Simple Recurrent Layers\n",
    "\n",
    "Before we dive into something as complicated as LSTMs, Let's take a deeper look at simple recurrent layer weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neurons in the recurrent layer pass their output to the next layer, but also back to themselves. The input shape says that we'll be passing in one-dimensional inputs of unspecified length (the None is what makes it unspecified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_unit_SRNN = Sequential()\n",
    "one_unit_SRNN.add(SimpleRNN(units=1, input_shape=(None, 1), activation='linear', use_bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.4368719]], dtype=float32), array([[-1.]], dtype=float32)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_SRNN_weights = one_unit_SRNN.get_weights()\n",
    "one_unit_SRNN_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set the weights to whatever we want, to test out what happens with different weight values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_unit_SRNN_weights[0][0][0] = 1\n",
    "one_unit_SRNN_weights[1][0][0] = 1\n",
    "one_unit_SRNN.set_weights(one_unit_SRNN_weights)\n",
    "one_unit_SRNN.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then pass in different input values, to see what the model outputs.\n",
    "\n",
    "The code below passes in a single sample that has three time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_unit_SRNN.predict(numpy.array([ [[3], [3], [7]] ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A\n",
    "Figure out what the two weights in the one_unit_SRNN model control. Be sure to test your hypothesis thoroughly. Use different weights and different inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21.605]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_SRNN_weights[0][0][0] = 5\n",
    "one_unit_SRNN_weights[1][0][0] = 0.1\n",
    "one_unit_SRNN.set_weights(one_unit_SRNN_weights)\n",
    "one_unit_SRNN.predict(numpy.array([ [[1], [2], [3], [4]] ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10.5\n",
      "16.05\n",
      "21.605\n"
     ]
    }
   ],
   "source": [
    "print(1*5)\n",
    "print(1*5*0.1+2*5)\n",
    "print((1*5*0.1+2*5)*0.1 + 3*5)\n",
    "print(((1*5*0.1+2*5)*0.1 + 3*5)*0.1 + 4 *5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first weight is multiplied against everything\n",
    "For an array of 'n' elements, the second weight is raised to the 'n - i' power and then multiplied against that value\n",
    "\n",
    "This means that the first weight is being applied to the inputs. Each value is multiplied by 5 once, because they are only multiplied against that weight when being inputted\n",
    "\n",
    "The second weight is applied to the previous output. The first value is multiplied by the 2nd weight three times, because the model has three outputs. Meanwhile, the fourth and final input is not multiplied by the 2nd weight, becaues the model is done inputting values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Slightly larger simple recurrent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_unit_SRNN = Sequential()\n",
    "two_unit_SRNN.add(SimpleRNN(units=2, input_shape=(None, 1), activation='linear', use_bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.0588845,  1.3168381]], dtype=float32),\n",
       " array([[ 0.03392483, -0.9994244 ],\n",
       "        [-0.9994244 , -0.03392483]], dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_unit_SRNN_weights = two_unit_SRNN.get_weights()\n",
    "two_unit_SRNN_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_unit_SRNN_weights[0][0][0] = 1\n",
    "two_unit_SRNN_weights[0][0][1] = 1\n",
    "two_unit_SRNN_weights[1][0][0] = 0\n",
    "two_unit_SRNN_weights[1][0][1] = 1\n",
    "two_unit_SRNN_weights[1][1][0] = 0\n",
    "two_unit_SRNN_weights[1][1][1] = 1\n",
    "two_unit_SRNN.set_weights(two_unit_SRNN_weights)\n",
    "two_unit_SRNN.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This passes in a single sample with four time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_unit_SRNN.predict(numpy.array([ [[3], [3], [7], [5]] ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B\n",
    "What do each of the six weights of the two_unit_SRNN control? Again, test out your hypotheses carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b, c, d, e, f = (1, 1, 0, 0 , 0.25, 0)\n",
    "two_unit_SRNN_weights[0][0][0] = a\n",
    "two_unit_SRNN_weights[0][0][1] = b\n",
    "two_unit_SRNN_weights[1][0][0] = c\n",
    "two_unit_SRNN_weights[1][0][1] = d\n",
    "two_unit_SRNN_weights[1][1][0] = e\n",
    "two_unit_SRNN_weights[1][1][1] = f\n",
    "two_unit_SRNN.set_weights(two_unit_SRNN_weights)\n",
    "#3, 3, 7, 5\n",
    "two_unit_SRNN.predict(numpy.array([ [[4], [5], [8], [6]] ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0 4 6.0 5.0 9.25 8.0 8.0 6.0\n"
     ]
    }
   ],
   "source": [
    "def unit1(input1, u1, u2):\n",
    "    return input1 * a + u1 * c + u2 * e\n",
    "def unit2(input2, u1, u2):\n",
    "    return input2 * b + u1 * d + u2 * f\n",
    "sum1_0 = unit1(4, 0, 0)\n",
    "sum2_0 = unit2(4, 0, 0)\n",
    "sum1_1 = unit1(5, sum1_0, sum2_0)\n",
    "sum2_1 = unit2(5, sum1_0, sum2_0)\n",
    "sum1_2 = unit1(8, sum1_1, sum2_1)\n",
    "sum2_2 = unit2(8, sum1_1, sum2_1)\n",
    "sum1_3 = unit1(6, sum1_2, sum2_2)\n",
    "sum2_3 = unit2(6, sum1_2, sum2_2)\n",
    "print(sum1_0, sum2_0, sum1_1, sum2_1, sum1_2, sum2_2, sum1_3, sum2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unit1 and unit2 functions are effectively a recreation of the recurrent units in the neural network. The units take an input and the output from itself and the other unit.\n",
    "\n",
    "It has been a while, so I don't remember the exact process I used to find out what each weight did. It was clear that weights A and B changed the input, because when weights C,D,E,and F were set to 0, the last input was simply multiplied by weight A or B to get a result. \n",
    "\n",
    "I could also tell that weight C was similar to the 2nd weight from Part A, since when C was set to a value, and D, E, and F were set to 0, the results were similar to Part A. However, I struggled to figure out the pattern when both C and D were non-zero numbers. I think somehow I figured out that weight E was similar to weight C. \n",
    "\n",
    "The current weights are an example of a case where the output does not rapidly grow. Since both weights D and F are zero for unit 2, this means unit 2 does not have any memory, and the output of unit 2 is based on the input only. Unit 1 has weight C at zero, which means it forgets its own output. Weight E is not zero, and this weight is multiplied against the result of unit 2. \n",
    "\n",
    "Unit 1's output is the input plus the output of Unit 2, and Unit 2's output is the current input. Unit 2 is forgetting everything, and Unit 1 is forgetting everything except Unit 2, which is already forgetting, so these two units will keep resetting to zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A is the weight for the input to unit 1\n",
    "\n",
    "B is the weight for the input to unit 2\n",
    "\n",
    "C is the weight for unit1 to unit1 (self)\n",
    "\n",
    "D is the weight for unit1 to unit2\n",
    "\n",
    "E is the weight for unit2 to unit1\n",
    "\n",
    "F is the weight for unit2 to unit2 (self)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: Exploring LSTMs (Optional Extension)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_unit_LSTM = Sequential()\n",
    "one_unit_LSTM.add(LSTM(units=1, input_shape=(None, 1),\n",
    "                       activation='linear', recurrent_activation='linear',\n",
    "                       use_bias=False, unit_forget_bias=False,\n",
    "                       kernel_initializer='zeros',\n",
    "                       recurrent_initializer='zeros',\n",
    "                       return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 0., 0., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_LSTM_weights = one_unit_LSTM.get_weights()\n",
    "one_unit_LSTM_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 0., 1., 1.]], dtype=float32),\n",
       " array([[0., 0., 0., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_LSTM_weights[0][0][0] = 1\n",
    "one_unit_LSTM_weights[0][0][1] = 0\n",
    "one_unit_LSTM_weights[0][0][2] = 1\n",
    "one_unit_LSTM_weights[0][0][3] = 1\n",
    "one_unit_LSTM_weights[1][0][0] = 0\n",
    "one_unit_LSTM_weights[1][0][1] = 0\n",
    "one_unit_LSTM_weights[1][0][2] = 0\n",
    "one_unit_LSTM_weights[1][0][3] = 0\n",
    "one_unit_LSTM.set_weights(one_unit_LSTM_weights)\n",
    "one_unit_LSTM.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  1.],\n",
       "        [  2.],\n",
       "        [ 16.],\n",
       "        [ 99.],\n",
       "        [ 34.],\n",
       "        [144.],\n",
       "        [675.]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_LSTM_weights[0][0][0] = 1\n",
    "one_unit_LSTM_weights[0][0][1] = 1\n",
    "one_unit_LSTM_weights[0][0][2] = 1\n",
    "one_unit_LSTM_weights[0][0][3] = 1\n",
    "one_unit_LSTM_weights[1][0][0] = 0\n",
    "one_unit_LSTM_weights[1][0][1] = 0\n",
    "one_unit_LSTM_weights[1][0][2] = 0\n",
    "one_unit_LSTM_weights[1][0][3] = 0\n",
    "one_unit_LSTM.set_weights(one_unit_LSTM_weights)\n",
    "one_unit_LSTM.predict(numpy.array([ [[1], [1], [2], [3], [1], [2], [3]] ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C (Optional Extension)\n",
    "Conceptually, the [LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) has several _gates_:\n",
    "\n",
    "* __Forget gate__: these weights allow some long-term memories to be forgotten.\n",
    "* __Input gate__: these weights decide what new information will be added to the context cell.\n",
    "* __Output gate__: these weights decide what pieces of the new information and updated context will be passed on to the output.\n",
    "\n",
    "It also has a __cell__ that can hold onto information from the current input (as well as things it has remembered from previous inputs), so that it can be used in later outputs.\n",
    "\n",
    "Identify which weights in the one_unit_LSTM model are connected with the context and which are associated with the three gates. This is considerably more difficult to do by looking at the inputs and outputs, so you could also treat this as a code reading exercise and look through the keras code to find the answer.\n",
    "\n",
    "_Note_: The output from the predict call is what the linked explanation calls $h_{t}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] [[1.]] [[1.]] [[1.]] [[0.]] [[0.]] [[0.]] [[0.]]\n"
     ]
    }
   ],
   "source": [
    "W = one_unit_LSTM.layers[0].get_weights()[0]\n",
    "U = one_unit_LSTM.layers[0].get_weights()[1]\n",
    "units = int(int(one_unit_LSTM.layers[0].trainable_weights[0].shape[1])/4)\n",
    "W_i = W[:, :units] #input\n",
    "W_f = W[:, units: units * 2] #forget\n",
    "W_c = W[:, units * 2: units * 3] #cell state\n",
    "W_o = W[:, units * 3:] #output\n",
    "\n",
    "U_i = U[:, :units] #input\n",
    "U_f = U[:, units: units * 2] #forget\n",
    "U_c = U[:, units * 2: units * 3] #cell state\n",
    "U_o = U[:, units * 3:] #output\n",
    "print(W_i, W_f, W_c, W_o, U_i, U_f, U_c, U_o)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the first 4 weights are 1 and the last 4 weights are 0, the behavior can be predicted\n",
    "I predicted that for input a, b, c, \n",
    "\n",
    "output_0 = a^3 = (0/a + a) * a^2\n",
    "\n",
    "output_1 = (output_0)/a + b) * b^2\n",
    "\n",
    "output_2 = (output_1/b + c) * c^2\n",
    "\n",
    "I don't know what the last 3 weights do, but making the 5th, 7th, and 8th weights = 1 will make the output infinity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For inputs 1, 1, 2, 3, 1, 2, 3, we expect:\n",
    "\n",
    "output_0 = 1^3 = 1\n",
    "\n",
    "output_1 = (1/1+ 1) * 1^2 = 2\n",
    "\n",
    "output_2 = (2/1 + 2) * 2^2 = 4 * 4 = 16\n",
    "\n",
    "output_3 = (16/2 + 3) * 3^2 = 11 * 9 = 99\n",
    "\n",
    "output_4 = (99/3 + 1) * 1^2 = 34\n",
    "\n",
    "output_5 = (34/1 + 2) * 2^2 = 36 * 4 = 144\n",
    "\n",
    "output_6 = (144/2 + 3) * 3^2 = 75 * 9 = 675\n",
    "\n",
    "As we can see from above, the actual output matches this prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
